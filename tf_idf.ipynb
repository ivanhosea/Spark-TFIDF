{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5567eec8-8ab2-4c52-accf-d4d4a932dfe9",
   "metadata": {},
   "source": [
    "## INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d086d77-e95d-44dd-9102-1736e1e253be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "# Read Config\n",
    "config = configparser.ConfigParser()\n",
    "config.read('tfidf_config.properties')\n",
    "SPARK_MASTER = config.get('tfidf', 'spark_master')\n",
    "SPARK_DRIVER_HOST = config.get('tfidf', 'spark_driver_host')\n",
    "SPARK_DRIVER_BINDADDRES = config.get('tfidf', 'spark_driver_bindaddress')\n",
    "TF_UDF_JAR_PATH = config.get('tfidf', 'tf_udf_jar_path')\n",
    "HDFS_URL = config.get('tfidf', 'hdfs_url')\n",
    "HADOOP_USER_NAME = config.get('tfidf', 'hadoop_user_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68221674-0438-4083-86fa-9987f6d2bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, IntegerType, DoubleType\n",
    "from pyspark.sql.functions import regexp_replace, lower, split, explode, col, collect_list, struct, udf, count, array, trim, log, lit\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.sql import SparkSession, Row\n",
    "import os\n",
    "\n",
    "# os.environ['PYSPARK_PYTHON'] = \"/home/user0170809/pyspark_venv1/bin/python\"\n",
    "# os.environ['PYSPARK_PYTHON'] = \"./environment/bin/python\"\n",
    "os.environ[\"HADOOP_USER_NAME\"] = HADOOP_USER_NAME\n",
    "\n",
    "# Create a SparkSession with a specific master using builder.config\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TF_IDF\") \\\n",
    "    .config(\"spark.master\", SPARK_MASTER) \\\n",
    "    .config(\"spark.driver.host\", SPARK_DRIVER_HOST) \\\n",
    "    .config(\"spark.driver.bindAddress\", SPARK_DRIVER_BINDADDRES) \\\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"33554432\") \\\n",
    "    .config(\"spark.executor.memory\", \"2G\") \\\n",
    "    .config(\"spark.memory.storageFraction\", \"0.05\") \\\n",
    "    .config(\"spark.hadoop.dfs.blocksize\", \"16777216\") \\\n",
    "    .config(\"spark.hadoop.parquet.block.size\", \"16777216\") \\\n",
    "    .config(\"spark.hadoop.dfs.replication\", \"1\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.5\") \\\n",
    "    .config(\"spark.jars\", TF_UDF_JAR_PATH) \\\n",
    "    .getOrCreate()\n",
    "#.config(\"spark.sql.shuffle.partitions\", \"179\") \\\n",
    "#.config(\"spark.executor.instances\", \"1\") \\\n",
    "#.config(\"spark.executor.cores\", \"2\") \\\n",
    "#.config(\"spark.archives\", \"/home/user1083408/pyspark_venv1.tar.gz#environment\") \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "542f7197-03c2-408f-877d-9f2f4907eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"url\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"text\", StringType(), True)\n",
    "])\n",
    "\n",
    "hdfs_input = f'hdfs://{HDFS_URL}/wiki2'\n",
    "#hdfs_input1 = f'hdfs://{HDFS_URL}/wiki2/part-00000-03018fbe-cac8-46a1-8b7a-70cb9751b15f-c000.snappy.parquet'\n",
    "#hdfs_input2 = f'hdfs://{HDFS_URL}/wiki2/part-00000-06fd7f28-a724-4eb0-a97a-73b002720b89-c000.snappy.parquet'\n",
    "#df = spark.read.schema(schema).parquet(hdfs_input1, hdfs_input2).select('id', 'text')\n",
    "df = spark.read.schema(schema).parquet(hdfs_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0313a37-cb25-4259-b581-3f76088f55e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_count = df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46094a86-58a3-41bb-9c91-d5bc69eb98f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = 1704000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "709fee93-c760-4b66-ab14-f5cd445fa8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = 37600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db998801-7623-420a-afbb-0ad147b3578c",
   "metadata": {},
   "source": [
    "## CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cd7ec7f-58b7-4638-a26d-e47b07473b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING (as text)\n",
    "\n",
    "# remove newline\n",
    "df_rm_newline = df.withColumn(\"text\", regexp_replace(\"text\", \"\\n\", \" \"))\n",
    "\n",
    "# select to only alphanumeric\n",
    "df_alphanum = df_rm_newline.withColumn(\"text\", regexp_replace(\"text\", \"[^a-zA-Z\\s]\", \" \"))\n",
    "\n",
    "# replace multi space with single space\n",
    "df_one_space = df_alphanum.withColumn(\"text\", regexp_replace(\"text\", \"\\s+\", \" \")).withColumn(\"text\", trim(\"text\"))\n",
    "\n",
    "# lowercase\n",
    "df_lower = df_one_space.withColumn(\"text\", lower(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d08d07a-51a5-4ac3-a8bb-09b9dc69fd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT TEXT TO WORDS ARRAY\n",
    "df_split_words = df_lower.withColumn(\"words\", split(col(\"text\"), \" \")).drop('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "108b898b-12fd-4621-bc8f-4f1c8ea81f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING (as array of words)\n",
    "\n",
    "# remove stop word\n",
    "df_rm_stopword = StopWordsRemover(inputCol=\"words\", outputCol=\"words_nostop\").transform(df_split_words).drop('words').withColumnRenamed(\"words_nostop\", \"words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f8d89b-1042-4756-b687-fabd441b62c3",
   "metadata": {},
   "source": [
    "## TERM-DOC COUNT WITH UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ccfe2d4-a37f-42d6-a94d-b5a32588d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_term_frequency(words_list):\n",
    "    word_count = len(words_list)\n",
    "    word_count_dict = {}\n",
    "    for word in words_list:\n",
    "        if word in word_count_dict:\n",
    "            word_count_dict[word] += 1\n",
    "        else:\n",
    "            word_count_dict[word] = 1\n",
    "    return [{\"term\": word, \"frequency\": count / word_count} for word, count in word_count_dict.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f665f465-d75d-4c58-8c6d-a58e8b6ee010",
   "metadata": {},
   "source": [
    "### (1a) Python UDF, Non-Deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cee8cce-ae5a-4208-aea2-154ee48569b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_term_frequency = udf(f_term_frequency, ArrayType(StructType([\n",
    "    StructField(\"term\", StringType()),\n",
    "    StructField(\"frequency\", DoubleType())\n",
    "]))).asNondeterministic()\n",
    "\n",
    "df_term_frequency = df_rm_stopword.select(col(\"id\").alias(\"doc_id\"), udf_term_frequency(\"words\").alias(\"term_frequency\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab8026-9e74-4429-a4d5-489d8be5fd4f",
   "metadata": {},
   "source": [
    "### (1b) Python UDF, Deterministic + Cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e65856f-02c2-44d1-b67d-b8c3df02233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_term_frequency = udf(f_term_frequency, ArrayType(StructType([\n",
    "    StructField(\"term\", StringType()),\n",
    "    StructField(\"frequency\", DoubleType())\n",
    "])))\n",
    "\n",
    "df_term_frequency = df_rm_stopword.select(col(\"id\").alias(\"doc_id\"), udf_term_frequency(\"words\").alias(\"term_frequency\")).persist(StorageLevel.MEMORY_ONLY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209965b9-705e-4848-bfc8-fb5be26dc228",
   "metadata": {},
   "source": [
    "### (1c) Scala UDF Cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cae93f00-7579-4276-b066-b17f67ca0851",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rm_stopword.createOrReplaceTempView(\"v_cleaned\")\n",
    "\n",
    "spark.udf.registerJavaFunction(\"udf_term_frequency\", \"com.scalaudf.TermFrequencyUDF\", ArrayType(StructType([\n",
    "    StructField(\"term\", StringType()),\n",
    "    StructField(\"frequency\", DoubleType())\n",
    "])))\n",
    "\n",
    "df_term_frequency = spark.sql(\"\"\"\n",
    "SELECT id AS doc_id, udf_term_frequency(words) AS term_frequency\n",
    "FROM v_cleaned\n",
    "\"\"\").persist(StorageLevel.MEMORY_ONLY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812d5741-801d-4eb8-81c0-3a238273214d",
   "metadata": {},
   "source": [
    "### (2) Explode & Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "178835d8-1a7e-47f3-8536-840dd4b55163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode group\n",
    "df_explode = df_term_frequency.withColumn(\"term_frequency\", explode(col(\"term_frequency\")))\n",
    "\n",
    "# Unstruct\n",
    "df_unstruct = df_explode.select('doc_id', col(\"term_frequency.term\"), col('term_frequency.frequency'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f198715-8fe6-4af1-ba36-4a7066858f3d",
   "metadata": {},
   "source": [
    "### (3a) Cache -> RepartitionByRange -> Group & Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b1d5084-a505-4b9b-805b-fc04c6478800",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unstruct_persisted = df_unstruct.persist(StorageLevel.DISK_ONLY)\n",
    "\n",
    "df_repart_range = df_unstruct_persisted.repartitionByRange(200, \"term\")\n",
    "\n",
    "df_termdoc = df_repart_range.groupBy(\"term\").agg(collect_list(struct(\"doc_id\", \"frequency\")).alias(\"term_frequency_array\"), (log(df_count / count(\"*\")) / log(lit(10))).alias(\"idf\"))\n",
    "\n",
    "df_termdoc_ordered = df_termdoc.orderBy(\"term\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b2534e-ceee-454f-82d9-ac889393f01a",
   "metadata": {},
   "source": [
    "### (3b) Group By -> Order By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5047589-cf38-4a08-86be-0fe7ffc26936",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unstruct.createOrReplaceTempView(\"v_word_count\")\n",
    "\n",
    "df_termdoc = spark.sql(f\"\"\"\n",
    "with cte as (\n",
    "SELECT term, COLLECT_LIST(STRUCT(doc_id, frequency)) AS term_frequency_array, log({df_count} / count(*)) / log(10) as idf\n",
    "FROM v_word_count\n",
    "GROUP BY term\n",
    ")\n",
    "SELECT term, TRANSFORM(term_frequency_array, x -> STRUCT(x.doc_id as doc_id, x.frequency * idf as tfidf)) as term_tfidf_array\n",
    "FROM cte\n",
    "\"\"\")\n",
    "\n",
    "df_termdoc_ordered = df_termdoc.sort(\"term\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584be2d8-fa9d-4429-b28c-a3491a8818d8",
   "metadata": {},
   "source": [
    "### (3c) Group By (Cache) -> Order By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1339a8c3-7b65-4acb-827a-fd0723cb9873",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unstruct.createOrReplaceTempView(\"v_word_count\")\n",
    "\n",
    "df_termdoc = spark.sql(f\"\"\"\n",
    "with cte as (\n",
    "SELECT term, COLLECT_LIST(STRUCT(doc_id, frequency)) AS term_frequency_array, log({df_count} / count(*)) / log(10) as idf\n",
    "FROM v_word_count\n",
    "GROUP BY term\n",
    ")\n",
    "SELECT term, TRANSFORM(term_frequency_array, x -> STRUCT(x.doc_id as doc_id, x.frequency * idf as tfidf)) as term_tfidf_array\n",
    "FROM cte\n",
    "\"\"\")\n",
    "\n",
    "df_termdoc_cache = df_termdoc.persist(StorageLevel.DISK_ONLY)\n",
    "\n",
    "df_termdoc_ordered = df_termdoc_cache.sort(\"term\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed72d8ae-05f0-468b-b432-9e017487be19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_termdoc_ordered.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74332df8-8bf8-401a-84b5-f82f059f9a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[doc_id: string, term: string, frequency: double]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unstruct_persisted.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a56ca652-d741-4953-8bbf-8502701e7090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[doc_id: string, term_frequency: array<struct<term:string,frequency:double>>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_term_frequency.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33915ad6-d7c9-4bb7-9441-443ed901525a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[term: string, term_frequency_array: array<struct<doc_id:string,frequency:double>>, idf: double]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_termdoc.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aedf47-4306-45ae-b590-7da1a5b75c21",
   "metadata": {},
   "source": [
    "## TERM-DOC COUNT WITH EXPLODE + GROUP BY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1b3b29c-54d8-4422-a46c-38d47c9eb4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cached = df_rm_stopword.select('id', 'words').persist(StorageLevel.MEMORY_ONLY)\n",
    "\n",
    "df_explode = df_cached.select(col(\"id\").alias('doc_id'), explode(col(\"words\")).alias('term'))\n",
    "\n",
    "df_term_doc = df_explode.groupBy(\"doc_id\", \"term\").agg(count(\"*\").alias(\"frequency\"))\n",
    "\n",
    "df_term_doc.createOrReplaceTempView(\"v_word_count\")\n",
    "\n",
    "df_termdoc = spark.sql(f\"\"\"\n",
    "with cte as (\n",
    "SELECT term, COLLECT_LIST(STRUCT(doc_id, frequency)) AS term_frequency_array, log({df_count} / count(*)) / log(10) as idf\n",
    "FROM v_word_count\n",
    "GROUP BY term\n",
    ")\n",
    "SELECT term, TRANSFORM(term_frequency_array, x -> STRUCT(x.doc_id as doc_id, x.frequency * idf as tfidf)) as term_tfidf_array\n",
    "FROM cte\n",
    "\"\"\")\n",
    "\n",
    "df_termdoc_ordered = df_termdoc.sort(\"term\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8afc578-ce03-4301-a351-6ae99a1525d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cached.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb940a8-19af-43df-84aa-6a415a6ed6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_termdoc_ordered.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a67c6d-c439-4f25-b814-0efca7fb4e0d",
   "metadata": {},
   "source": [
    "## SAVE TO HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5991217-41e4-4d72-a862-351e27761eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_output = f'hdfs://{HDFS_URL}/wiki_out4'\n",
    "df_termdoc_ordered.write.parquet(hdfs_output, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc95add-d4bc-4523-b385-84b4da601e9f",
   "metadata": {},
   "source": [
    "## VIEW HDFS FILE RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e67d79-5e27-4b48-8077-b57161020318",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_path1 = f'hdfs://{HDFS_URL}/wiki_out/part-00000-8deffe4c-8667-440b-b25c-53e3911a6917-c000.snappy.parquet'\n",
    "df = spark.read.parquet(hdfs_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72f9bc6-70b2-4b41-b8d4-a9c13b5ef243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python env2",
   "language": "python",
   "name": "env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
